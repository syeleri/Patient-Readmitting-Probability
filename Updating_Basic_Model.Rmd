---
title: "Basic_Model"
author: "Santosh"
date: "September 1, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
rm(list = ls(all=TRUE))
```

# Pulling the data from csv file to R

# Importing data from Patientdata.csv
```{r}


PatientData <- read.csv('Patientdata.csv', header = T)




```
`

# Importing data from Hospitaldata.csv

```{r}


HospitalData <- read.csv('Hospitaldata.csv', header = T)




```



# Importing data from Diagnosisdata.csv

```{r}


DiagnosisData <- read.csv('Diagnosisdata.csv', header = T)



```


#Merging all three dataframes

# To start with merge "PatientData" and "HospitalData"

```{r}

library(data.table)

# merging two DataFrame by "PatientID" and "Istrain"

merged_PatHos_df1 = merge(PatientData,HospitalData,by.x=c("patientID","istrain"),by.y = c("patientID","istrain"))




# merging the combined dataframe of "PatientData" and "HospitalData" with "DiagnosisData"

merged_df_Final = merge(merged_PatHos_df1,DiagnosisData,by.x=c("patientID","istrain"),by.y = c("patientID","istrain"))



```

#EDA - Exploring the data in the final DataFrame - merged_df_Final

```{r}
# summary(merged_df_Final)


```
```{r}
# str(merged_df_Final)
```





# Creating a new column for number of days spent in hospital, which is differnce in discharge date and admission date
# And eliminating columns for "Admission_date" and "Discahrge_date"
```{r}



library(lubridate)

# converting the datatype to "Date"" type.

 merged_df_Final$Admission_date<-as_date(merged_df_Final$Admission_date)
 
 merged_df_Final$Discharge_date<-as_date(merged_df_Final$Discharge_date)
 
 
 
 
# Finding the difference in the days  and assigning to a new column "diff_in_days"

merged_df_Final$diff_in_days<- difftime(merged_df_Final$Discharge_date ,merged_df_Final$Admission_date , units = c("days"))



# # Eliminating columns for "Admission_date" and "Discahrge_date"

merged_df_Final<-merged_df_Final[,!(names(merged_df_Final) %in% c("Admission_date","Discharge_date"))] 




# updating diff_in_days to numeric

merged_df_Final$diff_in_days<-as.integer(as.numeric(merged_df_Final$diff_in_days))

 
```



#saperating Train and Test data

```{r}


#picking up the columen which have "istrain" column value as"1", for train data

Final_Train_Data<-merged_df_Final[merged_df_Final$istrain==1,]






#picking up the columen which have "istrain" column value as"0", for test data

Final_Test_Data<-merged_df_Final[merged_df_Final$istrain==0,]





```

# Eliminating the columsn which won't be contribute for model building going ahead
```{r}
#Elimnating column "istrain" from final test and train data, as the purpose of splitting the data into train and test is complete

Train_Data<-Final_Train_Data[,!(names(Final_Train_Data) %in% c("istrain"))] 



Test_Data<-Final_Test_Data[,!(names(Final_Test_Data) %in% c("istrain"))] 


```


```{r}
#  Removing the column for "AdmissionID", as we have the "Patient ID"" column.

# Removing "Weight" column as, 30569 values out of 31513 are"NA"" values.

# Removing columsn for "metformin.rosiglitazone" and "acetohexamide", as they have only one level

Train_Data_Final<-Train_Data[,!(names(Train_Data) %in% c("AdmissionID","weight","metformin.rosiglitazone","acetohexamide","max_glu_serum","repaglinide","nateglinide","chlorpropamide","troglitazone","medical_specialty","tolbutamide","acarbose","miglitol","tolazamide","glyburide.metformin","glipizide.metformin","metformin.pioglitazone"))]

Train_Data_Final<-Train_Data_Final[, !colnames(Train_Data_Final) %in% c("patientID")]







# Test_Data_Final<-Test_Data[,!(names(Test_Data) %in% c("AdmissionID","weight","metformin.rosiglitazone","acetohexamide"))]



```

# Further exploring train and test data frame

```{r}
 # str(Train_Data_Final)

```


#Data processing and EDA on Train data



# Imputation - CEntral 
```{r}
library(RANN)
library(DMwR)
library(caret)

# conducting Central Imputation
set.seed(786)

# stratified split

train_rows <- createDataPartition(Train_Data_Final$Target, p = 0.7, list = F)


# splitting into test and train

Train_Data_Final <- Train_Data_Final[train_rows, ]

Test_Data_Final <- Train_Data_Final[-train_rows, ]



#Imputation

Train_Data_Final <- centralImputation(Train_Data_Final)

Test_Data_Final<-centralImputation(Test_Data_Final)



# train_data<-Train_Data_Final[, !colnames(Train_Data_Final) %in% c("patientID")]
# 
# test_data<-Test_Data_Final[, !colnames(Test_Data_Final) %in% c("patientID")]

train_data<-Train_Data_Final

test_data<-Test_Data_Final
# head(train_data)
# 
# head(test_data)
# 
# sum(is.na(train_data))
# 
# sum(is.na(test_data))

# table(train_data$Target)
# 
# table(test_data$Target)
# 
# 
# ggplot(data = train_data, aes(x = Target)) +
#   geom_bar(fill="green") +
# xlab("Bivalues")
# 
# ggplot(data = test_data, aes(x = Target)) +
#   geom_bar(fill="green") +
# xlab("Bivalues")

# Train_Data_Final <- centralImputation(Train_Data_Final)
# 
# Test_Data_Final<-centralImputation(Test_Data_Final)
# 
# 
# 
# train_data<-Train_Data_Final[, !colnames(Train_Data_Final) %in% c("patientID")]
# 
# test_data<-Test_Data_Final[, !colnames(Test_Data_Final) %in% c("patientID")]

str(train_data)

```


<!-- Building basic Logistic regression model -->
```{r}
log_reg <- glm(Target~., data = train_data, family = binomial)

```

#Summary of the model

```{r}
summary(log_reg)
```

#* Calcuating the Deviance Residuals
```{r}
Devaince_residuals = residuals(log_reg, "deviance")
summary(Devaince_residuals)
```

#* Calculating the log likeli hood
```{r}
logLik(log_reg)
log_reg
```

#List of predictions
```{r}
prob_train <- predict(log_reg, type = "response")
prob_train
```
```{r}
library(ROCR)

 pred <- prediction(prob_train, train_data$Target)



perf <- performance(pred, measure="tpr", x.measure="fpr")

 plot(perf, col=rainbow(10), colorize=T, print.cutoffs.at=seq(0,1,0.01))
```

```{r}
perf_auc <- performance(pred, measure="auc")

# Access the auc score from the performance object

auc <- perf_auc@y.values[[1]]

print(auc)
```


```{r}


prob_test <- predict(log_reg, test_data, type = "response")

# preds_test <- ifelse(prob_test > 0.2,"Yes","No")

preds_test <- ifelse(prob_test > 0.35,"Yes","No")

# print(preds_test)

table(preds_test)

# preds_test_submission<-data.frame(preds_test)
# 
# write.csv(preds_test_submission,file="submission1.csv")
```

```{r}
test_data_labs <- test_data$Target

conf_matrix <- table(test_data_labs, preds_test)

print(conf_matrix)
```
```{r}
specificity <- conf_matrix[1, 1]/sum(conf_matrix[1, ])

print(specificity)
```

```{r}
sensitivity <- conf_matrix[2, 2]/sum(conf_matrix[2, ])

print(sensitivity)
```
```{r}
accuracy <- sum(diag(conf_matrix))/sum(conf_matrix)

print(accuracy)
```




                  #########################Building Random forest model##############
                  
```{r}

library(randomForest)
set.seed(123)




# str(train_data)



#remving "Medical_speciality" column , assuming it wont be having effect on the diabetic treatment.

train_data$medical_specialty<-NULL

str(train_data)

model = randomForest(Target ~ ., data=train_data, 
                     keep.forest=TRUE, ntree=200)

print(model)
```

#Finding important attribute
```{r}
model$importance
```
```{r}
rf_Imp_Attr = data.frame(model$importance)
rf_Imp_Attr = data.frame(row.names(rf_Imp_Attr),rf_Imp_Attr[,1])
rf_Imp_Attr



```
# Sorting the important attibutes
```{r}
colnames(rf_Imp_Attr) = c('Attributes', 'Importance')
rf_Imp_Attr = rf_Imp_Attr[order(rf_Imp_Attr$Importance, decreasing = TRUE),]
rf_Imp_Attr
```
```{r}
varImpPlot(model)
```
```{r}
# Building Model on top 16 important attribute

top_Imp_Attr = as.character(rf_Imp_Attr$Attributes[1:10])

set.seed(015)

# Build the classification model using randomForest
model_Imp = randomForest(Target~.,
                         data=train_data[,c(top_Imp_Attr,"Target")], 
                         keep.forest=TRUE,ntree=100) 

print(model_Imp)
```
```{r}
table(train_data$Target)
```

```{r}
model_Imp$importance
```

```{r}
# Predicting on Train Data
pred_Train = predict(model_Imp, train_data[,top_Imp_Attr],
                     type="response", norm.votes=TRUE)


# Build confusion matrix and find accuracy   
cm_Train = table("actual" = train_data$Target, 
                 "predicted" = pred_Train);
cm_Train
```
```{r}
# Calculating Accuracy
accu_Train_Imp = sum(diag(cm_Train))/sum(cm_Train)
accu_Train_Imp
```

```{r}
rm(pred_Train, cm_Train)
```

```{r}
# Prediction on test data

# Predicton Test Data
pred_Test = predict(model_Imp, test_data[,top_Imp_Attr],
                    type="response", norm.votes=TRUE)

# Build confusion matrix and find accuracy   
cm_Test = table("actual" = test_data$Target, 
                "predicted" = pred_Test);
cm_Test
```
```{r}
#  Accuracy on test data

accu_Test_Imp = sum(diag(cm_Test))/sum(cm_Test)

# rm(pred_Test, cm_Test)

accu_Test_Imp
```


```{r}
preds_test_submission_RF<-data.frame(pred_Test)

write.csv(preds_test_submission_RF,file="submission2.csv")
```
#####################Knn and condensed KNN#########

```{r}
library(class)

# train_data
# test_data

# bankdata_trainwithoutclass = subset(train_data,select=-c(Target))
#   bankdata_testwithoutclass = subset(test_data,select=-c(Target))
# 
# # N = 1/3/5/7
#   Neigh <-3
#   pred=knn(bankdata_trainwithoutclass, bankdata_testwithoutclass, train_data$Target, k = Neigh)
#   a=table(pred,test_data$Target)
#   accu= sum(diag(a))/sum(a)
#   accu

str(train_data)
```

